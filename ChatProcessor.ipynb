{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported dependencies.\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import io\n",
    "import threading\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "from keras.models import model_from_json\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "#Import my functions from the sentiment analysis\n",
    "import IntentClassification.Intent_Classification_Lai\n",
    "from IntentClassification.Intent_Classification_Lai import predictions\n",
    "from IntentClassification.Intent_Classification_Lai import get_final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def followlog(chatlog):\n",
    "    chatlog.seek(0,2)\n",
    "    sleeptime = 0.1\n",
    "    while True:\n",
    "        line = chatlog.readline()\n",
    "        if not line:\n",
    "            time.sleep(sleeptime)\n",
    "            continue\n",
    "        yield line\n",
    "\n",
    "def processline(line):\n",
    "    [date, line] = line.split(\"_\",1)\n",
    "    [timeofday, channel, text] = line.split(\",\",2)\n",
    "    channel = channel.split(\"#\",-1)[1]\n",
    "    return [date, timeofday, channel, text]\n",
    "\n",
    "def wordcountline(dictionary,text):\n",
    "    words = re.split('\\s|; |, |\\*|\\n|\\. |\\.|\\r|(\\?)',text)\n",
    "    bannedwords = {'':True, None:True}\n",
    "    words = list(set(words))\n",
    "    for word in words:\n",
    "        if word in bannedwords: pass\n",
    "        elif word in dictionary:\n",
    "            dictionary[word] += 1\n",
    "        else:\n",
    "            dictionary[word] = 1\n",
    "    return dictionary\n",
    "\n",
    "def animatedplot(channelnumlines, channelxs, channelys, channelsentiments):\n",
    "    #organizes the plotting for many channels\n",
    "    channelnumber = 0\n",
    "    for channel in channelnumlines:\n",
    "        # Add x and y to lists\n",
    "        channelxs[channel].append(strftime(\"%H:%M:%S\", gmtime()))#The year month date, optional,can be called here %Y-%m-%d \n",
    "        channelys[channel].append(channelnumlines[channel])\n",
    "        # Limit x and y lists to 10 items\n",
    "        channelxs[channel] = channelxs[channel][-10:]\n",
    "        channelys[channel] = channelys[channel][-10:]\n",
    "        latestchannelsentiment = max(channelsentiments[channel].items(), key=operator.itemgetter(1))[0]\n",
    "        channelnumber +=1\n",
    "        singleplot(channel, channelxs, channelys, latestchannelsentiment, channelnumber)#Plot the number of messages for each channel\n",
    "        channelnumlines[channel]=0#Reset the number of lines for each channel\n",
    "        channelsentiments[channel] = initializeintentcounter(unique_intent)#Reset channel intent\n",
    "    return [channelnumlines, channelsentiments]\n",
    "    \n",
    "def singleplot(channel, channelxs, channelys, latestchannelsentiment, channelnumber):\n",
    "    #Plots for a single channel\n",
    "    # Draw x and y lists\n",
    "    plt.cla()\n",
    "    numchannels = len(channelnumlines)\n",
    "    plt.subplot(numchannels, 1,  channelnumber)\n",
    "    plt.plot(channelxs[channel], channelys[channel], marker='x')\n",
    "    # Format plot\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.subplots_adjust(bottom=0.30)\n",
    "    plt.title('Number of messages for #%s; channel sentiment: %s' % (channel, latestchannelsentiment))\n",
    "    plt.ylabel('Number of messages')\n",
    "    plt.xlabel('Time')\n",
    "    plt.draw()\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "def initializenumlines(channel, channelnumlines, channelys, channelxs):\n",
    "    channelnumlines[channel]=0\n",
    "    channelys[channel]=[]\n",
    "    channelxs[channel]=[]\n",
    "    return [channelnumlines, channelys, channelxs]\n",
    "    \n",
    "def initializeintentcounter(unique_intent):\n",
    "    intentdictionary = {}\n",
    "    for intent in unique_intent:\n",
    "        intentdictionary[intent] = 0\n",
    "    return intentdictionary\n",
    "\n",
    "def getmessagesentiment(channelsentiment, word_tokenizer, text, model, max_length, unique_intent):\n",
    "    sentiment = get_final_output(predictions(word_tokenizer, text, model, max_length), unique_intent, 'classify')\n",
    "    channelsentiment[sentiment] += 1#Perform an intent classification\n",
    "    return channelsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/laitcl/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/laitcl/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Load chat classification model\n",
    "# Model reconstruction from JSON file\n",
    "with open('IntentClassification/model_architecture.json', 'r') as f1:\n",
    "    model = model_from_json(f1.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('IntentClassification/model_weights.h5')\n",
    "\n",
    "#Load Word Tokenizer\n",
    "with open('IntentClassification/tokenizer.pickle', 'rb') as handle:\n",
    "    word_tokenizer = pickle.load(handle)\n",
    "    \n",
    "#Load Max Length of a message\n",
    "with open('IntentClassification/maxlen.txt', 'r') as f2:\n",
    "    max_length = int(f2.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a042b84f80d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#begin logging chat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloglines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfollowlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloglines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeofday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannelnumlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1a07d784f167>\u001b[0m in \u001b[0;36mfollowlog\u001b[0;34m(chatlog)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleeptime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    logfile = open(\"TwitchBot/messagelog.csv\",\"r\")\n",
    "    #Setup tracking variables\n",
    "    #For capturing data at set time intervalsmodel\n",
    "    beginningtime=time.time()\n",
    "    starttime = time.time()\n",
    "    logtimeinterval = 5\n",
    "    #For counting messages\n",
    "    channelnumlines = {} \n",
    "    channelxs = {}\n",
    "    channelys = {}\n",
    "    #For intent classification\n",
    "    channelsentiments = {}\n",
    "    unique_intent = ['question', 'disappointment', 'funny', 'neutral']\n",
    "    \n",
    "    #begin logging chat\n",
    "    loglines = followlog(logfile)\n",
    "    for line in loglines:\n",
    "        [date,timeofday,channel,text] = processline(line)\n",
    "        if channel not in channelnumlines:\n",
    "            #If channel wasn't previously tracked, start tracking\n",
    "            [channelnumlines, channelys, channelxs] = initializenumlines(channel, channelnumlines, channelys, channelxs)\n",
    "            channelsentiments[channel] = initializeintentcounter(unique_intent)\n",
    "        channelsentiments[channel] = getmessagesentiment(channelsentiments[channel], word_tokenizer, text, model, max_length, unique_intent)#Increment a sentiment\n",
    "        channelnumlines[channel] += 1#Increment the number of messages in that channel\n",
    "        \n",
    "        #Every interval, perform analysis\n",
    "        if time.time() - starttime >= logtimeinterval:\n",
    "            #clear_output()\n",
    "            [channelnumlines, channelsentiments] = animatedplot(channelnumlines, channelxs, channelys, channelsentiments)#Plot the number of messages for each channel\n",
    "            starttime = time.time()#Reset the start time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ChatProcessor.ipynb to script\n",
      "[NbConvertApp] Writing 5870 bytes to ChatProcessor.py\n"
     ]
    }
   ],
   "source": [
    "#Export this notebook as a script\n",
    "#!jupyter nbconvert --to script ChatProcessor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
